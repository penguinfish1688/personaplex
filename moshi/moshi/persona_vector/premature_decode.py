"""Premature decode utilities for inspecting layer-wise text logits.

Expected input: `output_hidden.pt` generated by `fdb.py --save-hidden`.

Payload schema (saved by `run_batch_inference(..., save_hidden_payload=True)`):
    - `text_hidden_layers`: torch.FloatTensor[T, L, D]
        T: generated token count (from input.wav processing only)
        L: number of main text transformer layers
        D: hidden size
    - `text_attention_weights`: list[torch.FloatTensor[L, H, K_t]]
        H: attention heads
        K_t: causal key length at token t (can vary)
    - `token_ids`: torch.LongTensor[T]
    - `token_names`: list[str]
    - `times`: torch.FloatTensor[T]
    - `token_time_ranges_sec`: torch.FloatTensor[T, 2]
    - `frame_rate`: float (12.5 Hz)

Token-time alignment:
    token 0 -> [0, 1/12.5) seconds
    token t -> [t/12.5, (t+1)/12.5) seconds
"""

from __future__ import annotations

import argparse
from dataclasses import dataclass
from pathlib import Path
from typing import Optional, Sequence

import matplotlib.pyplot as plt
import numpy as np
import sentencepiece
import torch
import torch.nn.functional as F
from huggingface_hub import hf_hub_download

from moshi.models import loaders


SPECIAL_TOKEN_MAP = {
    0: "EPAD",
    1: "BOS",
    2: "EOS",
    3: "PAD",
}


@dataclass
class DecoderProjection:
    """Projection layers used to convert hidden states to text logits."""

    out_norm: Optional[torch.nn.Module]
    text_linear: torch.nn.Module


class DecodeData:
    """Per-token layer-wise decode information.

    Args:
        attention_weights: Optional `[L, H, K_t]` tensor for one token.
        hidden_states: `[L, D]` hidden states for one token across layers.
        projection: Decoder projection used to convert hidden states to logits.
        tokenizer: Text tokenizer for token visualization.
    """

    def __init__(
        self,
        attention_weights: Optional[torch.Tensor],
        hidden_states: torch.Tensor,
        projection: DecoderProjection,
        tokenizer: sentencepiece.SentencePieceProcessor,
    ):
        self.attention_weights = attention_weights
        self.hidden_states = hidden_states.float()
        self._projection = projection
        self._tokenizer = tokenizer
        self.logits = self._calculate_logits()  # [L, V]
        self.token_ids = self._greedy_decode()  # [L]
        self.tokens = [self._id_to_piece(int(t)) for t in self.token_ids.tolist()]

    def _calculate_logits(self) -> torch.Tensor:
        """Project hidden states `[L, D]` to logits `[L, vocab_size]`."""
        x = self.hidden_states
        if self._projection.out_norm is not None:
            x = self._projection.out_norm(x)
        logits = self._projection.text_linear(x)
        if logits.dim() != 2:
            raise RuntimeError(f"Unexpected logits shape: {tuple(logits.shape)}")
        return logits.float()

    def _greedy_decode(self) -> torch.Tensor:
        """Greedy token ids for every layer: `[L]`."""
        return torch.argmax(self.logits, dim=-1)

    def get_final_output(self) -> tuple[int, str, torch.Tensor]:
        """Return final-layer token id, piece, and logits vector."""
        final_id = int(self.token_ids[-1].item())
        return final_id, self._id_to_piece(final_id), self.logits[-1]

    def jsd(self, layer_n: int) -> float:
        """Jensen-Shannon divergence vs final layer distribution."""
        if layer_n < 0 or layer_n >= self.logits.shape[0]:
            raise IndexError(f"layer_n={layer_n} out of range [0, {self.logits.shape[0] - 1}]")
        p = self.logits[layer_n]
        q = self.logits[-1]
        return float(_jsd_from_logits(p, q).item())

    def _id_to_piece(self, token_id: int) -> str:
        if token_id in SPECIAL_TOKEN_MAP:
            return SPECIAL_TOKEN_MAP[token_id]
        piece = self._tokenizer.id_to_piece(token_id)
        return piece.replace("‚ñÅ", " ") if piece is not None else f"<{token_id}>"


def _jsd_from_logits(logits_p: torch.Tensor, logits_q: torch.Tensor) -> torch.Tensor:
    p = F.softmax(logits_p.float(), dim=-1)
    q = F.softmax(logits_q.float(), dim=-1)
    m = 0.5 * (p + q)
    eps = torch.finfo(p.dtype).eps
    kl_pm = torch.sum(p * (torch.log(p + eps) - torch.log(m + eps)))
    kl_qm = torch.sum(q * (torch.log(q + eps) - torch.log(m + eps)))
    return 0.5 * (kl_pm + kl_qm)


def plot_logits_evolution(decode_data_list: list[DecodeData], output_path: str):
    """Plot layer-wise JSD heatmap and most likely token at each cell.

    Spec:
        - x-axis: token sequence index
        - y-axis: layer index (1..L)
        - cell color: JSD(layer, final-layer) where white=more similar, blue=less similar
        - text in each cell: greedy token for that layer and token position
    """
    if len(decode_data_list) == 0:
        raise ValueError("decode_data_list is empty")

    num_tokens = len(decode_data_list)
    num_layers = int(decode_data_list[0].logits.shape[0])

    jsd_grid = np.zeros((num_layers, num_tokens), dtype=np.float32)
    token_grid: list[list[str]] = [["" for _ in range(num_tokens)] for _ in range(num_layers)]

    for t, item in enumerate(decode_data_list):
        if item.logits.shape[0] != num_layers:
            raise ValueError("All DecodeData entries must have the same number of layers")
        for layer_idx in range(num_layers):
            jsd_grid[layer_idx, t] = item.jsd(layer_idx)
            token_grid[layer_idx][t] = item.tokens[layer_idx]

    fig_w = max(10.0, num_tokens * 0.7)
    fig_h = max(8.0, num_layers * 0.24)
    fig, ax = plt.subplots(figsize=(fig_w, fig_h), dpi=150)

    im = ax.imshow(jsd_grid, aspect="auto", cmap="Blues", origin="upper")
    cbar = fig.colorbar(im, ax=ax)
    cbar.set_label("JSD vs final layer")

    for y in range(num_layers):
        for x in range(num_tokens):
            token_txt = token_grid[y][x].replace("\n", " ")
            ax.text(x, y, token_txt, ha="center", va="center", fontsize=6, color="black")

    ax.set_xlabel("Token index")
    ax.set_ylabel("Layer (1..L)")
    ax.set_xticks(np.arange(num_tokens))
    ax.set_yticks(np.arange(num_layers))
    ax.set_yticklabels([str(i + 1) for i in range(num_layers)])
    ax.set_title("Premature decode: layer-wise logits evolution")

    fig.tight_layout()
    out_path = Path(output_path)
    out_path.parent.mkdir(parents=True, exist_ok=True)
    fig.savefig(out_path)
    plt.close(fig)


def decode_preview(token_names: Sequence[str], chunk: int = 10) -> str:
    """Return a compact preview string for final output tokens.

    Uses `.` for `PAD` / `EPAD`.
    """
    clean = ["." if t in {"PAD", "EPAD"} else t for t in token_names]
    lines = []
    for i in range(0, len(clean), chunk):
        tokens = " ".join(clean[i : i + chunk])
        lines.append(f"{i:<4d} {tokens}")
    return "\n".join(lines)


def _resolve_hidden_path(root_dir: Path, sample_number: int) -> Path:
    return root_dir / str(sample_number) / "output_hidden.pt"


def _load_decoder_projection(
    *,
    hf_repo: str,
    moshi_weight: Optional[str],
    device: str,
) -> DecoderProjection:
    if moshi_weight is None:
        moshi_weight = hf_hub_download(hf_repo, loaders.MOSHI_NAME)  # type: ignore
    lm = loaders.get_moshi_lm(moshi_weight, device=device, cpu_offload=(device == "cpu"))
    lm.eval()
    return DecoderProjection(out_norm=lm.out_norm, text_linear=lm.text_linear)


def _load_tokenizer(hf_repo: str, tokenizer_path: Optional[str]) -> sentencepiece.SentencePieceProcessor:
    if tokenizer_path is None:
        tokenizer_path = hf_hub_download(hf_repo, loaders.TEXT_TOKENIZER_NAME)  # type: ignore
    return sentencepiece.SentencePieceProcessor(tokenizer_path)  # type: ignore


def premature_decode(
    hidden_payload: dict,
    projection: DecoderProjection,
    tokenizer: sentencepiece.SentencePieceProcessor,
    start: int,
    end: int,
) -> list[DecodeData]:
    """Build DecodeData list for token range [start, end)."""
    hidden = hidden_payload["text_hidden_layers"]
    if not isinstance(hidden, torch.Tensor) or hidden.dim() != 3:
        raise ValueError("Expected payload['text_hidden_layers'] with shape [T, L, D]")

    t_total = int(hidden.shape[0])
    start = max(0, start)
    end = t_total if end < 0 else min(end, t_total)
    if start >= end:
        raise ValueError(f"Invalid range [{start}, {end}) for total tokens {t_total}")

    attention_list = hidden_payload.get("text_attention_weights", [None] * t_total)
    if len(attention_list) != t_total:
        attention_list = [None] * t_total

    decode_data_list: list[DecodeData] = []
    for t in range(start, end):
        decode_data_list.append(
            DecodeData(
                attention_weights=attention_list[t],
                hidden_states=hidden[t],
                projection=projection,
                tokenizer=tokenizer,
            )
        )
    return decode_data_list


def main():
    ap = argparse.ArgumentParser("premature_decode")
    ap.add_argument("--root-dir", type=str, required=True, help="Root dir containing <n>/output_hidden.pt")
    ap.add_argument("-n", "--sample-number", type=int, required=True, help="Sample folder number under root-dir")
    ap.add_argument("--hidden-path", type=str, default=None, help="Direct path to output_hidden.pt (overrides root-dir/-n)")
    ap.add_argument("-s", "--start", type=int, default=0, help="Start token index (inclusive)")
    ap.add_argument("-e", "--end", type=int, default=-1, help="End token index (exclusive), -1 means end")
    ap.add_argument("--output", type=str, default=None, help="Output figure path")
    ap.add_argument("--preview-output", action="store_true", help="Print final decoded output preview")
    ap.add_argument("--hf-repo", type=str, default=loaders.DEFAULT_REPO)
    ap.add_argument("--tokenizer", type=str, default=None)
    ap.add_argument("--moshi-weight", type=str, default=None)
    ap.add_argument("--device", type=str, default="cpu")
    args = ap.parse_args()

    root_dir = Path(args.root_dir)
    hidden_path = Path(args.hidden_path) if args.hidden_path else _resolve_hidden_path(root_dir, args.sample_number)
    if not hidden_path.exists():
        raise FileNotFoundError(f"Hidden payload not found: {hidden_path}")

    payload = torch.load(hidden_path, map_location="cpu")
    if "text_hidden_layers" not in payload:
        raise ValueError("Unsupported payload: missing key 'text_hidden_layers'")

    token_names = payload.get("token_names", [])
    if args.preview_output:
        print(decode_preview(token_names))
        return

    tokenizer = _load_tokenizer(args.hf_repo, args.tokenizer)
    projection = _load_decoder_projection(
        hf_repo=args.hf_repo,
        moshi_weight=args.moshi_weight,
        device=args.device,
    )

    decode_data = premature_decode(
        hidden_payload=payload,
        projection=projection,
        tokenizer=tokenizer,
        start=args.start,
        end=args.end,
    )

    if args.output:
        output_path = Path(args.output)
    else:
        end_idx = args.end if args.end >= 0 else payload["text_hidden_layers"].shape[0]
        output_path = hidden_path.with_name(f"logits_evolution_{args.start}_{end_idx}.png")

    plot_logits_evolution(decode_data, str(output_path))
    print(f"Saved figure to {output_path}")


if __name__ == "__main__":
    main()
